# AWS-S3-to-Azure-DataLake-ETL-Pipeline

This tutorial shows you how to use the Data Factory Copy Data tool to load data from Amazon Web Services S3 service into Azure Data Lake Storage Gen2.

### To implement this, we need to create the following resources:
- Create AWS s3 bucket.
- Create Azure data lake storage gen2.
- Create Azure data factory.
- Use the copy activity to create a pipeline.
- Monitor the pipeline and activity runs.
